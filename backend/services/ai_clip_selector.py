from openai import OpenAI
import difflib
import random
import re
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# âœ… Uses API key from environment variable
client = OpenAI(api_key=os.getenv("OPEN_AI_API_KEY"))

# ðŸ”¹ Step 1: Ask LLM to identify viral/emotional/storytelling moments
def generate_highlights_from_full_transcript(full_text, top_n=3):
    prompt = f"""
You are a content analyst assistant helping a creator make short, engaging TikTok videos from a podcast or interview.

Your task is to identify the top {top_n} most compelling moments that meet one or more of these criteria:
- A powerful or emotional story is being shared
- A personal or vulnerable moment is being explained
- A clear explanation or insight into an interesting topic is being given
- A moment that feels shocking, funny, relatable, or likely to go viral on social media

For each moment, return:
- A short description of what's happening
- The actual quote or exact wording from the transcript (1â€“5 sentences max)
- Ensure different styles of moments are chosen for variety.

Only include quotes that exactly exist in the transcript.

Transcript:
\"\"\"
{full_text}
\"\"\"
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.9,  # ðŸ”¹ Higher temp for more diverse responses
        max_tokens=1000
    )

    return response.choices[0].message.content


# ðŸ”¹ Step 2: Match each quote to a transcript segment using string similarity
def find_segment_for_quote(quote, segments, fuzz_threshold=0.6):
    best_match = None
    highest_ratio = 0
    for seg in segments:
        ratio = difflib.SequenceMatcher(None, quote, seg["text"]).ratio()
        if ratio > highest_ratio:
            best_match = seg
            highest_ratio = ratio
    return best_match if highest_ratio >= fuzz_threshold else None


# ðŸ”¹ Step 3: Expand selected segments to meet minimum clip duration
def expand_segment(match, segments, min_duration=60.0):
    if not match:
        return None

    match_index = segments.index(match)
    start_idx = match_index
    end_idx = match_index

    start_time = float(segments[start_idx]["start"])
    end_time = float(segments[end_idx]["end"])
    total_duration = end_time - start_time

    # Expand to neighboring segments until we hit min duration
    while total_duration < min_duration:
        can_expand_before = start_idx > 0
        can_expand_after = end_idx < len(segments) - 1

        if can_expand_before and (not can_expand_after or total_duration < min_duration):
            start_idx -= 1
        elif can_expand_after:
            end_idx += 1
        else:
            break  # Can't expand anymore

        start_time = float(segments[start_idx]["start"])
        end_time = float(segments[end_idx]["end"])
        total_duration = end_time - start_time

    combined_text = " ".join(seg["text"] for seg in segments[start_idx:end_idx + 1])

    return {
        "start": start_time,
        "end": end_time,
        "matched_segment": combined_text
    }


# ðŸ”¹ Step 4: Ensure at least `top_n` clips & add randomness
def process_llm_highlights(llm_output, segments, min_duration=60.0, top_n=3):
    highlights = []
    matches = re.findall(r'"([^"]+)"', llm_output)  # Extract quoted strings

    for quote in matches:
        match = find_segment_for_quote(quote, segments)
        if match:
            highlight = expand_segment(match, segments, min_duration)
            if highlight:
                highlight["quote"] = quote
                highlights.append(highlight)

    # If fewer than top_n, select random segments
    while len(highlights) < top_n:
        random_segment = random.choice(segments)
        highlight = expand_segment(random_segment, segments, min_duration)
        if highlight and highlight not in highlights:
            highlight["quote"] = "Randomly selected engaging moment"
            highlights.append(highlight)

    return highlights


# ðŸ”¹ Step 5: Main pipeline function
def run_pipeline_and_return_highlights(segments, top_n=3, min_duration=60.0):
    full_transcript = " ".join(seg["text"] for seg in segments)
    print("\nðŸ” Asking LLM to find top emotional/viral/story moments...\n")
    llm_output = generate_highlights_from_full_transcript(full_transcript, top_n)
    print("ðŸ§  LLM Response:\n", llm_output)

    highlights = process_llm_highlights(llm_output, segments, min_duration=min_duration, top_n=top_n)
    return highlights





# from openai import OpenAI
# import difflib
# import re
# import os
# from dotenv import load_dotenv

# # Load environment variables from .env file
# load_dotenv()

# # âœ… Uses API key from environment variable
# client = OpenAI(api_key=os.getenv("OPEN_AI_API_KEY"))

# # ðŸ”¹ Step 1: Ask LLM to identify viral/emotional/storytelling moments
# def generate_highlights_from_full_transcript(full_text, top_n=3):
#     prompt = f"""
# You are a content analyst assistant helping a creator make short, engaging TikTok videos from a podcast or interview.

# Your task is to identify the top {top_n} most compelling segments that meet one or more of these criteria:
# - A powerful or emotional story is being shared
# - A personal or vulnerable moment is being explained
# - A clear explanation or insight into an interesting topic is being given
# - A moment that feels shocking, funny, relatable, or likely to go viral on social media

# For each moment, return:
# - A short description of what's happening
# - The actual quote or exact wording from the transcript (1â€“5 sentences max)

# Only include quotes that exactly exist in the transcript.

# Transcript:
# \"\"\"
# {full_text}
# \"\"\"
# """
#     response = client.chat.completions.create(
#         model="gpt-4-turbo",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.7,
#         max_tokens=1000
#     )

#     return response.choices[0].message.content


# # ðŸ”¹ Step 2: Match each quote to a transcript segment using string similarity
# def find_segment_for_quote(quote, segments, fuzz_threshold=0.6):
#     best_match = None
#     highest_ratio = 0
#     for seg in segments:
#         ratio = difflib.SequenceMatcher(None, quote, seg["text"]).ratio()
#         if ratio > highest_ratio:
#             best_match = seg
#             highest_ratio = ratio
#     return best_match if highest_ratio >= fuzz_threshold else None


# # ðŸ”¹ Step 3: Process LLM output, expand short segments to meet 60s min
# def process_llm_highlights(llm_output, segments, min_duration=60.0):
#     highlights = []
#     matches = re.findall(r'"([^"]+)"', llm_output)  # extract quoted strings

#     for quote in matches:
#         match = find_segment_for_quote(quote, segments)
#         if not match:
#             continue

#         match_index = segments.index(match)
#         start_idx = match_index
#         end_idx = match_index

#         # Convert to float to calculate duration
#         start_time = float(segments[start_idx]["start"])
#         end_time = float(segments[end_idx]["end"])
#         total_duration = end_time - start_time

#         # Expand to neighboring segments until we hit min duration
#         while total_duration < min_duration:
#             can_expand_before = start_idx > 0
#             can_expand_after = end_idx < len(segments) - 1

#             if can_expand_before and (not can_expand_after or total_duration < min_duration):
#                 start_idx -= 1
#             elif can_expand_after:
#                 end_idx += 1
#             else:
#                 break  # Can't expand anymore

#             start_time = float(segments[start_idx]["start"])
#             end_time = float(segments[end_idx]["end"])
#             total_duration = end_time - start_time

#         combined_text = " ".join(seg["text"] for seg in segments[start_idx:end_idx + 1])

#         highlights.append({
#             "quote": quote,
#             "start": start_time,
#             "end": end_time,
#             "matched_segment": combined_text
#         })

#     return highlights


# # ðŸ”¹ Step 4: Main pipeline function to call from FastAPI or elsewhere
# def run_pipeline_and_return_highlights(segments, top_n=3, min_duration=60.0):
#     full_transcript = " ".join(seg["text"] for seg in segments)
#     print("\nðŸ” Asking LLM to find top emotional/viral/story moments...\n")
#     llm_output = generate_highlights_from_full_transcript(full_transcript, top_n)
#     print("ðŸ§  LLM Response:\n", llm_output)

#     highlights = process_llm_highlights(llm_output, segments, min_duration=min_duration)
#     return highlights


